{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12871616,"sourceType":"datasetVersion","datasetId":8142263}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, Input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.preprocessing import StandardScaler, label_binarize\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve, auc\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nimport time\nfrom sklearn.metrics import accuracy_score, classification_report","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T13:17:09.203497Z","iopub.execute_input":"2025-08-28T13:17:09.203811Z","iopub.status.idle":"2025-08-28T13:17:22.231580Z","shell.execute_reply.started":"2025-08-28T13:17:09.203794Z","shell.execute_reply":"2025-08-28T13:17:22.230833Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dir = \"/kaggle/input/coffee-bean-tanvir/train\"\ntest_dir = \"/kaggle/input/coffee-bean-tanvir/test\"\n\n# Training Data Generator (with validation split)\n# ======================\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    brightness_range=[0.8,1.2],\n    horizontal_flip=True,\n    fill_mode='nearest',\n    validation_split=0.2   # 20% of training data for validation\n)\n\n# Training generator\ntrain_gen = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(128,128),\n    batch_size=32,\n    class_mode='categorical',\n    shuffle=True,\n    subset='training'    # <-- this is the training subset\n)\n\n# Validation generator\nval_gen = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(128,128),\n    batch_size=32,\n    class_mode='categorical',\n    shuffle=False,\n    subset='validation'  # <-- this is the validation subset\n)\n\n# ======================\n# Test Data Generator (final evaluation)\n# ======================\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntest_gen = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(128,128),\n    batch_size=32,\n    class_mode='categorical',\n    shuffle=False\n)\n\n# Quick sanity check\n# ======================\nprint(\"Train classes mapping:\", train_gen.class_indices)\nprint(\"Validation classes mapping:\", val_gen.class_indices)\nprint(\"Test classes mapping:\", test_gen.class_indices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T13:17:22.232303Z","iopub.execute_input":"2025-08-28T13:17:22.232672Z","iopub.status.idle":"2025-08-28T13:17:22.569591Z","shell.execute_reply.started":"2025-08-28T13:17:22.232656Z","shell.execute_reply":"2025-08-28T13:17:22.569065Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def se_block(feature_map, ratio=8):\n    channel = feature_map.shape[-1]\n    \n    # Squeeze: Global Average Pooling\n    se = layers.GlobalAveragePooling2D()(feature_map)\n    se = layers.Reshape((1,1,channel))(se)\n    \n    # Excitation: Two FC layers\n    se = layers.Dense(channel // ratio, activation='relu', kernel_initializer='he_normal', use_bias=True)(se)\n    se = layers.Dense(channel, activation='sigmoid', kernel_initializer='he_normal', use_bias=True)(se)\n    \n    # Scale feature map\n    x = layers.Multiply()([feature_map, se])\n    return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T13:17:22.570237Z","iopub.execute_input":"2025-08-28T13:17:22.570442Z","iopub.status.idle":"2025-08-28T13:17:22.574991Z","shell.execute_reply.started":"2025-08-28T13:17:22.570421Z","shell.execute_reply":"2025-08-28T13:17:22.574413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_se_cnn(input_shape=(128,128,3), num_classes=4):\n    inputs = Input(shape=input_shape)\n\n    # Conv Block 1\n    x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(inputs)\n    x = layers.MaxPooling2D((2,2))(x)\n    x = se_block(x)\n\n    # Conv Block 2\n    x = layers.Conv2D(64, (3,3), activation='relu', padding='same')(x)\n    x = layers.MaxPooling2D((2,2))(x)\n    x = se_block(x)\n\n    # Conv Block 3\n    x = layers.Conv2D(128, (3,3), activation='relu', padding='same')(x)\n    x = layers.MaxPooling2D((2,2))(x)\n    x = se_block(x)\n\n    # Global Average Pooling (feature output)\n    gap = layers.GlobalAveragePooling2D()(x)\n\n    # Dense head for training only\n    dense = layers.Dense(256, activation='relu')(gap)\n    dense = layers.Dropout(0.5)(dense)\n    outputs = layers.Dense(num_classes, activation='softmax')(dense)\n\n    model = models.Model(inputs, outputs)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T13:17:22.575771Z","iopub.execute_input":"2025-08-28T13:17:22.575994Z","iopub.status.idle":"2025-08-28T13:17:22.593643Z","shell.execute_reply.started":"2025-08-28T13:17:22.575980Z","shell.execute_reply":"2025-08-28T13:17:22.593058Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_classes = train_gen.num_classes\nse_model = build_se_cnn(input_shape=(128,128,3), num_classes=num_classes)\n\nse_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nhistory = se_model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=20,\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T13:17:22.594333Z","iopub.execute_input":"2025-08-28T13:17:22.595081Z","iopub.status.idle":"2025-08-28T13:20:11.011705Z","shell.execute_reply.started":"2025-08-28T13:17:22.595058Z","shell.execute_reply":"2025-08-28T13:20:11.011176Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_extractor = models.Model(\n    inputs=se_model.input,\n    outputs=se_model.layers[-4].output   # GAP output before Dense\n)\ndef extract_features(model, generator):\n    features = []\n    labels = []\n    for i in range(len(generator)):\n        x_batch, y_batch = generator[i]\n        feat = model.predict(x_batch, verbose=0)\n        features.append(feat)\n        labels.append(np.argmax(y_batch, axis=1))\n    features = np.vstack(features)\n    labels = np.hstack(labels)\n    return features, labels\nX_train, y_train = extract_features(feature_extractor, train_gen)\nX_val, y_val     = extract_features(feature_extractor, val_gen)\nX_test, y_test   = extract_features(feature_extractor, test_gen)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T13:20:11.013896Z","iopub.execute_input":"2025-08-28T13:20:11.014360Z","iopub.status.idle":"2025-08-28T13:20:25.309673Z","shell.execute_reply.started":"2025-08-28T13:20:11.014338Z","shell.execute_reply":"2025-08-28T13:20:25.309078Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply MinMaxScaler to the extracted features\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_val_scaled = scaler.transform(X_val)\nX_test_scaled = scaler.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T13:20:25.310404Z","iopub.execute_input":"2025-08-28T13:20:25.310616Z","iopub.status.idle":"2025-08-28T13:20:25.320572Z","shell.execute_reply.started":"2025-08-28T13:20:25.310598Z","shell.execute_reply":"2025-08-28T13:20:25.319962Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# XGBoost Classifier\n# ======================\nxgb_clf = XGBClassifier(\n    objective=\"multi:softprob\",\n    eval_metric=\"mlogloss\",\n    use_label_encoder=False,\n    random_state=42\n)\n\nxgb_clf.fit(X_train_scaled, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T13:20:25.321554Z","iopub.execute_input":"2025-08-28T13:20:25.321791Z","iopub.status.idle":"2025-08-28T13:20:25.694388Z","shell.execute_reply.started":"2025-08-28T13:20:25.321771Z","shell.execute_reply":"2025-08-28T13:20:25.693557Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---- Training ----\nstart_time = time.time()\nxgb_clf = XGBClassifier(\n    objective=\"multi:softprob\",\n    eval_metric=\"mlogloss\",\n    use_label_encoder=False,\n    random_state=42\n)\nxgb_clf.fit(X_train_scaled, y_train)\ntrain_time = time.time() - start_time\nprint(f\"Training Time: {train_time:.4f} seconds\")\n\n# ---- Validation ----\nstart_time = time.time()\ny_val_pred = xgb_clf.predict(X_val_scaled)\nval_time = time.time() - start_time\nprint(f\"Validation Prediction Time: {val_time:.4f} seconds\")\nprint(\"Validation Accuracy (XGBoost):\", accuracy_score(y_val, y_val_pred))\n\n# ---- Testing ----\nstart_time = time.time()\ny_test_pred = xgb_clf.predict(X_test_scaled)\ntest_time = time.time() - start_time\nprint(f\"Test Prediction Time: {test_time:.4f} seconds\")\nprint(\"Test Accuracy (XGBoost):\", accuracy_score(y_test, y_test_pred))\n\n# ---- Classification Report ----\nprint(classification_report(y_test, y_test_pred, target_names=list(train_gen.class_indices.keys())))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T13:20:25.695189Z","iopub.execute_input":"2025-08-28T13:20:25.695463Z","iopub.status.idle":"2025-08-28T13:20:26.046851Z","shell.execute_reply.started":"2025-08-28T13:20:25.695440Z","shell.execute_reply":"2025-08-28T13:20:26.046297Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot training and validation accuracy and loss\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(len(acc))\n\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T13:20:26.047534Z","iopub.execute_input":"2025-08-28T13:20:26.049115Z","iopub.status.idle":"2025-08-28T13:20:26.664534Z","shell.execute_reply.started":"2025-08-28T13:20:26.049095Z","shell.execute_reply":"2025-08-28T13:20:26.663743Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---- Predictions ----\ny_test_pred_xgb = xgb_model.predict(X_test_scaled)\n# For probability estimates, use predict_proba\ny_test_proba_xgb = xgb_model.predict_proba(X_test_scaled)\n\n\n# ---- Basic Metrics ----\nprint(\"Accuracy:\", accuracy_score(y_test, y_test_pred_xgb))\nprint(\"Precision:\", precision_score(y_test, y_test_pred_xgb, average='macro'))\nprint(\"Recall:\", recall_score(y_test, y_test_pred_xgb, average='macro'))\nprint(\"F1-score:\", f1_score(y_test, y_test_pred_xgb, average='macro'))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred_xgb))\n\n# ---- ROC-AUC Curves ----\n# Binarize labels for multi-class ROC\nclasses_present = np.unique(y_test)\ny_test_bin = label_binarize(y_test, classes=classes_present)\n\n# Only plot ROC if at least 2 classes are present\nif y_test_bin.shape[1] > 1:\n    plt.figure(figsize=(8,6))\n    for i in range(y_test_bin.shape[1]):\n        fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_test_proba_xgb[:, i])\n        plt.plot(fpr, tpr, label=f\"Class {list(train_gen.class_indices.keys())[classes_present[i]]} (AUC = {auc(fpr, tpr):.2f})\")\n    plt.plot([0,1],[0,1],'k--')\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.title(\"ROC Curves (Test Set)\")\n    plt.legend()\n    plt.show()\n\n    # Compute overall ROC-AUC\n    print(\"Test AUC:\", roc_auc_score(y_test_bin, y_test_proba_xgb, multi_class='ovr'))\nelse:\n    print(\"ROC-AUC skipped: less than 2 classes present in test set\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T13:20:26.665204Z","iopub.execute_input":"2025-08-28T13:20:26.665391Z","iopub.status.idle":"2025-08-28T13:20:26.864885Z","shell.execute_reply.started":"2025-08-28T13:20:26.665376Z","shell.execute_reply":"2025-08-28T13:20:26.864328Z"}},"outputs":[],"execution_count":null}]}